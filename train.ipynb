{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from config.config import args\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"%s\" % args.GPU_ID\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import lpips\n",
    "from model.VDM_PCD import VDM_PCD, model_fn_decorator\n",
    "from data.load_video_temporal import *\n",
    "from utils.loss_util import *\n",
    "from utils.common import *\n",
    "\n",
    "\n",
    "def val_epoch(args, ValImgLoader, model, model_fn_val, net_metric, epoch, save_path):\n",
    "    save_path = save_path + '/' + '%04d' % epoch\n",
    "    mkdir(save_path)\n",
    "    tbar = tqdm(ValImgLoader)\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    total_lpips = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(tbar):\n",
    "        loss, cur_psnr, cur_ssim, cur_lpips = model_fn_val(args, data, model, net_metric, save_path)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        avg_val_loss = total_loss / (batch_idx + 1)\n",
    "        total_psnr += cur_psnr\n",
    "        avg_val_psnr = total_psnr / (batch_idx + 1)\n",
    "        total_ssim += cur_ssim\n",
    "        avg_val_ssim = total_ssim / (batch_idx + 1)\n",
    "        total_lpips += cur_lpips\n",
    "        avg_val_lpips = total_lpips / (batch_idx + 1)\n",
    "        desc = 'Validation: Epoch %d, Avg. LPIPS = %.4f, Avg. PSNR = %.4f and SSIM = %.4f, Avg. Loss = %.5f' % (\n",
    "            epoch, avg_val_lpips, avg_val_psnr, avg_val_ssim, avg_val_loss)\n",
    "        tbar.set_description(desc)\n",
    "        tbar.update()\n",
    "\n",
    "    return avg_val_loss, avg_val_psnr, avg_val_ssim, avg_val_lpips\n",
    "\n",
    "\n",
    "def train_epoch(args, TrainImgLoader, model, model_fn, optimizer, epoch, iters, lr_scheduler):\n",
    "    tbar = tqdm(TrainImgLoader)\n",
    "    total_loss = 0\n",
    "    total_loss_temporal = 0\n",
    "    total_loss_reg = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(tbar):\n",
    "        loss, loss_temporal, loss_reg = model_fn(args, data, model, iters, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        iters += 1\n",
    "        lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / (batch_idx + 1)\n",
    "        total_loss_temporal += loss_temporal.item()\n",
    "        avg_train_loss_temporal = total_loss_temporal / (batch_idx + 1)\n",
    "        total_loss_reg += loss_reg.item()\n",
    "        avg_train_loss_reg = total_loss_reg / (batch_idx + 1)\n",
    "        desc = 'Training  : Epoch %d, Avg. Loss = %.5f, Avg. Loss Temporal = %.5f, Avg. Loss Reg = %.5f' % (\n",
    "            epoch, avg_train_loss, avg_train_loss_temporal, avg_train_loss_reg)\n",
    "        tbar.set_description(desc)\n",
    "        tbar.update()\n",
    "\n",
    "    return lr, avg_train_loss, iters\n",
    "\n",
    "\n",
    "def init():\n",
    "    \"\"\"\n",
    "    Initialize settings\n",
    "    \"\"\"\n",
    "\n",
    "    # Make dirs\n",
    "    mkdir(args.MODEL_DIR)\n",
    "    mkdir(args.VAL_RESULT_DIR)\n",
    "    mkdir(args.LOGS_DIR)\n",
    "    mkdir(args.VISUALS_DIR)\n",
    "    mkdir(args.NETS_DIR)\n",
    "\n",
    "    # GPU devices\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"%d\" % args.GPU_ID\n",
    "\n",
    "    # logger\n",
    "    logger = SummaryWriter(args.LOGS_DIR)\n",
    "\n",
    "    # LPIPS\n",
    "    net_metric_alex = lpips.LPIPS(net='alex').cuda()\n",
    "\n",
    "    # random seed\n",
    "    random.seed(args.SEED)\n",
    "    np.random.seed(args.SEED)\n",
    "    torch.manual_seed(args.SEED)\n",
    "    torch.cuda.manual_seed_all(args.SEED)\n",
    "    if args.SEED == 0:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    else:\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    return logger, net_metric_alex\n",
    "\n",
    "\n",
    "def load_checkpoint(model, load_epoch):\n",
    "    # import shutil\n",
    "    # shutil.copy('blend_vdm_pcd_shuffle_f3_i1_t2_mixup/model_dir/nets/checkpoint_000049.tar', args.NETS_DIR)\n",
    "\n",
    "    load_dir = args.NETS_DIR + '/checkpoint' + '_' + '%06d' % load_epoch + '.tar'\n",
    "    print('Loading pre-trained checkpoint %s' % load_dir)\n",
    "    avg_lpips = torch.load(load_dir)['avg_val_lpips']\n",
    "    avg_psnr = torch.load(load_dir)['avg_val_psnr']\n",
    "    avg_ssim = torch.load(load_dir)['avg_val_ssim']\n",
    "    print('Avg. LPIPS, PSNR and SSIM values recorded from the checkpoint: %f, %f, %f' % (avg_lpips, avg_psnr, avg_ssim))\n",
    "    model_state_dict = torch.load(load_dir)['state_dict']\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    learning_rate = torch.load(load_dir)['learning_rate']\n",
    "    iters = torch.load(load_dir)['iters']\n",
    "    print('Learning rate recorded from the checkpoint: %s' % str(learning_rate))\n",
    "\n",
    "    return learning_rate, iters\n",
    "\n",
    "\n",
    "def load_pretrain(model, load_dir):\n",
    "    print('Loading pre-trained checkpoint %s' % load_dir)\n",
    "    model_state_dict = torch.load(load_dir)['state_dict']\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger, net_metric = init()\n",
    "    learning_rate = args.BASE_LR\n",
    "    iters = 0\n",
    "    model = VDM_PCD(args).cuda()\n",
    "    if args.LOAD_EPOCH != 0:\n",
    "        learning_rate, iters = load_checkpoint(model, args.LOAD_EPOCH)\n",
    "\n",
    "    # # load pre-trained model\n",
    "    # if args.fhd_pretrain is not None:\n",
    "    #     load_pretrain(model, args.fhd_pretrain)\n",
    "\n",
    "    loss_fn = multi_VGGPerceptualLoss(lam_p=args.WEIGHT_PEC, lam_l=args.WEIGHT_L1).cuda()\n",
    "    ## no deep supervision loss\n",
    "    # loss_fn = single_VGGPerceptualLoss(lam_p=args.WEIGHT_PEC, lam_l=args.WEIGHT_L1).cuda()\n",
    "    optimizer = optim.Adam([{'params': model.parameters(), 'initial_lr': learning_rate}], lr=learning_rate, betas=(0.9, 0.999))\n",
    "    lr_scheduler = CosineAnnealingLR_warmup(args, optimizer, base_lr=args.BASE_LR, last_epoch=iters - 1, min_lr=1e-7)\n",
    "\n",
    "    # model_fn(criterion)\n",
    "    model_fn = model_fn_decorator(loss_fn=loss_fn)\n",
    "    model_fn_val = model_fn_decorator(loss_fn=loss_fn, mode='val')\n",
    "\n",
    "    # create dataloader\n",
    "    tr_input_list = sorted([file for file in os.listdir(args.TRAIN_DATASET + '/target') if (file.endswith('.jpg') or file.endswith('.png'))])\n",
    "    val_input_list = sorted([file for file in os.listdir(args.TEST_DATASET + '/target') if (file.endswith('.jpg') or file.endswith('.png'))])[0:-1:10]\n",
    "    TrainImgLoader = data.DataLoader(data_loader(args, tr_input_list, mode='train'),\n",
    "                                     batch_size=args.BATCH_SIZE,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=8,\n",
    "                                     pin_memory=True)\n",
    "    ValImgLoader = data.DataLoader(data_loader(args, val_input_list, mode='val'),\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=1)\n",
    "\n",
    "    # train and val metrics\n",
    "    avg_train_loss = 0\n",
    "    avg_val_psnr = 0\n",
    "    avg_val_ssim = 0\n",
    "    avg_val_lpips = 0\n",
    "    avg_val_loss = 0\n",
    "\n",
    "    for epoch in range(args.LOAD_EPOCH + 1, args.EPOCHS + 1):\n",
    "        print(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        learning_rate, avg_train_loss, iters = train_epoch(args, TrainImgLoader, model, model_fn,\n",
    "                                                           optimizer, epoch, iters, lr_scheduler)\n",
    "        if epoch % args.VAL_TIME == args.VAL_TIME - 1:\n",
    "            avg_val_loss, avg_val_psnr, avg_val_ssim, avg_val_lpips = val_epoch(args, ValImgLoader, model, model_fn_val,\n",
    "                                                                                net_metric, epoch, args.VAL_RESULT_DIR)\n",
    "        logger.add_scalar('Train/avg_loss', avg_train_loss, epoch)\n",
    "        logger.add_scalar('Validation/avg_psnr', avg_val_psnr, epoch)\n",
    "        logger.add_scalar('Validation/avg_ssim', avg_val_ssim, epoch)\n",
    "        logger.add_scalar('Validation/avg_lpips', avg_val_lpips, epoch)\n",
    "        logger.add_scalar('Validation/avg_val_loss', avg_val_loss, epoch)\n",
    "        logger.add_scalar('Train/learning_rate', learning_rate, epoch)\n",
    "\n",
    "        # Save the network per epoch with performance metrics as well\n",
    "        savefilename = args.NETS_DIR + '/checkpoint' + '_' + '%06d' % epoch + '.tar'\n",
    "        torch.save({\n",
    "            'learning_rate': learning_rate,\n",
    "            'iters': iters,\n",
    "            'avg_val_lpips': avg_val_lpips,\n",
    "            'avg_val_psnr': avg_val_psnr,\n",
    "            'avg_val_ssim': avg_val_ssim,\n",
    "            'state_dict': model.state_dict()\n",
    "        }, savefilename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
